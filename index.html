<!DOCTYPE html>
<html class="gr__ee_nthu_edu" lang="en">

<head>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta content="IE=edge" http-equiv="X-UA-Compatible">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Hongkai Wei" name="author">
  <title>Beyond Human Perception: Understanding Multi-Object World from Monocular View</title>

  <!-- CSS includes -->
  <link href="./asset/bootstrap.min.css" rel="stylesheet">
  <link href="./asset/css" rel="stylesheet" type="text/css">
  <link href="./asset/mystyle.css" rel="stylesheet">
</head>

<body data-gr-c-s-loaded="true">

  <div class="topnav" id="myTopnav">
    <a href="#header">Home</a>
    <a href="#abstract">Abstract</a>
    <a href="#framework">Framework</a>
    <a href="#dataset">Code&Dataset</a>
    <a href="#experiment">Experiment</a>
    <a class="icon" href="javascript:void(0);" onclick="toggleTopNav()">&#9776;</a>
  </div>

  <style>
    .justify {
      text-align: justify; /* 设置两端对齐 */
    }
  </style>

  <div class="container-fluid" id="header">
    <div class="row justify-content-center">
      <div class="col-12 text-center">
        <h1>
          <img src="imgs/Logo.png" alt="Logo" style="vertical-align: middle; height: 60px; margin-right: 15px;">
          Beyond Human Perception: Understanding Multi-Object World 
          <br>
          from Monocular View
        </h1>

        <br>
        <img src="./imgs/vs2.gif" alt="演示动画1" height="500">
        <br><br><br>
        <img src="./imgs/vs3.gif" alt="演示动画2" height="500">

        <div class="container" id="abstract">
          <h2>
          <img src="imgs/abstract.png" alt="Logo" style="vertical-align: middle; height: 40px; margin-right: 15px;">
          Abstract
          </h2>

          <body>
            <p class="justify">Language and binocular vision play a crucial role in human understanding of the world. Advancements in artificial intelligence have also made it possible for machines to develop 3D perception capabilities essential for high-level scene understanding. However, only monocular cameras are often available in practice due to cost and space constraints. Enabling machines to achieve accurate 3D understanding from a monocular view is practical but presents significant challenges. We introduce <strong>MonoMulti-3DVG</strong>, a novel task aimed at achieving multi-object 3D Visual Grounding (<strong>3DVG</strong>) based on monocular RGB images, allowing machines to better understand and interact with the 3D world. To this end, we construct a large-scale benchmark dataset, <strong>MonoMulti3D-ROPE</strong>, and propose a model, CyclopsNet that integrates a State-Prompt Visual Encoder (<strong>SPVE</strong>) module with a Denoising Alignment Fusion (<strong>DAF</strong>) module to achieve robust multi-modal semantic alignment and fusion. This leads to more stable and robust multi-modal joint representations for downstream tasks. Experimental results show that our method significantly outperforms existing techniques on the MonoMulti3D-ROPE dataset. 
            </p>
          </body>
        </div>
  
        <div class="container" id="framework">
          <h2 class="text-center">
          <img src="imgs/framework.png" alt="Logo" style="vertical-align: middle; height: 50px; margin-right: 15px;">Framework
          </h2>
          <p class="text-justify">
            The multi-modal processing module first obtains text features and all 3D objects. Then we obtain our state-prompt visual embeddings by passing the 2D image and state prompt through the State-Prompt Visual Encoder (<strong>SPVE</strong>). By modeling the textual and visual embeddings as Gaussian distributions and converging them pairwise with the multi-modal representations from the Query-Guided Joint Embedding (<strong>QGJE</strong>) module, we obtain robust and comprehensive multi-modal representations. Finally, the Kolmogorov-Arnold Network (<strong>KAN</strong>) is supervised by the Object-Text Matching (<strong>OTM</strong>) task to predict how well the object matches the query text.
          </p>
          <a href="#" target="_blank">
            <img height="550" src="imgs/fig_network.png" class="img-fluid mx-auto d-block" alt="Framework Diagram">
          </a>
        </div>
      </div>
    </div>
  </div>
  

  <div class="container" id="video">
    <h2>
      <img src="imgs/video.png" alt="Logo" style="vertical-align: middle; height: 50px; margin-right: 15px;"> Video Overview
    </h2>
    <div style="text-align:center;">
      <video width="1150" height="600" controls>
        <source src="imgs/cvpr_4177.mp4" type="video/mp4">
      </video>
    </div>
  </div>


  <div class="container" id="dataset">
    <h2><img src="imgs/code.png" alt="Logo" style="vertical-align: middle; height: 50px; margin-right: 15px;"> Code & 
      <img src="imgs/dataset.png" alt="Logo" style="vertical-align: middle; height: 50px; margin-right: 15px;">Dataset
    </h2>
    <strong>Monocular-Multi-Object 3D Visual Grounding (MonoMulti-3DVG) task:</strong> <br>
    MonoMulti-3DVG aims to extract the 3D information of all relevant objects from a given natural language query based on monocular RGB images, enabling machines to better understand and interact with the 3D world.<br>
    <br>
    <strong>Construction pipeline for our MonoMulti3D-ROPE dataset:</strong> <br>
    We first extract attribute information for each object within a scene, then randomly select a subset of those attributes. Later, we assign random values to the chosen attributes, ensuring that at least one object in the scene meets the randomly selected attribute values. We then populate a pre-designed prompt template with the selected attribute values, using ChatGPT to generate natural language descriptions that refer to one or multiple objects within the scene.
    <br>
    <div class="data">
      <p style="text-align:center;">       
        <a target="_blank"><img width=100% src="./imgs/fig_data.png"></a>
      </p>
    </div>
    <table class="three-line-table" style="text-align: center; width: 100%; border-collapse: collapse;">
      <caption>
          Statistical comparison of datasets for 3D Visual Grounding task, where `Num' refers to the number, `pc' denotes point cloud, `RGB' denotes RGB Image and `bbox' represents bounding box.
      </caption>
      <colgroup>
          <col style="width: 27%;"> <!-- Dataset 列 -->
          <col style="width: 5%;"> <!-- Expression Num. -->
          <col style="width: 5%;"> <!-- Exp. Length. -->
          <col style="width: 10%;"> <!-- Object Num. -->
          <col style="width: 5%;"> <!-- Range -->
          <col style="width: 10%;"> <!-- Visual Form -->
          <col style="width: 15%;"> <!-- Label 列 -->
          <col style="width: 5%;"> <!-- Scene -->
          <col style="width: 18%;">  <!-- Target -->
      </colgroup>
      <thead>
          <tr>
              <th>Dataset</th>
              <th>Expression Num.</th>
              <th>Exp. Length.</th>
              <th>Object Num.</th>
              <th>Range</th>
              <th>Visual Form</th>
              <th>Label</th>
              <th>Scene</th>
              <th>Target</th>
          </tr>
      </thead>
      <tbody>
          <tr>
              <td>ScanRefer</td>
              <td>51,583</td>
              <td>20.27</td>
              <td>11,046</td>
              <td>10m</td>
              <td>pc</td>
              <td>3D bbox</td>
              <td>Indoor</td>
              <td>Single target</td>
          </tr>
          <tr>
              <td>Sr3d</td>
              <td>83,572</td>
              <td>-</td>
              <td>8,863</td>
              <td>10m</td>
              <td>pc</td>
              <td>3D bbox</td>
              <td>Indoor</td>
              <td>Single target</td>
          </tr>
          <tr>
              <td>Nr3d</td>
              <td>41,503</td>
              <td>11.40</td>
              <td>5,879</td>
              <td>10m</td>
              <td>pc</td>
              <td>3D bbox</td>
              <td>Indoor</td>
              <td>Single target</td>
          </tr>
          <tr>
              <td>SUNRefer</td>
              <td>38,495</td>
              <td>16.30</td>
              <td>7,699</td>
              <td>--</td>
              <td>RGB-D</td>
              <td>3D bbox</td>
              <td>Indoor</td>
              <td>Single target</td>
          </tr>
          <tr>
              <td>STRefer</td>
              <td>5,458</td>
              <td>-</td>
              <td>3,581</td>
              <td>30m</td>
              <td>pc &amp; RGB</td>
              <td>3D bbox</td>
              <td>Outdoor</td>
              <td>Single target</td>
          </tr>
          <tr>
              <td>LifeRefer</td>
              <td>25,380</td>
              <td>-</td>
              <td>11,864</td>
              <td>30m</td>
              <td>pc &amp; RGB</td>
              <td>3D bbox</td>
              <td><strong>In/Outdoor</strong></td>
              <td>Single target</td>
          </tr>
          <tr>
              <td>Mono3DRefer</td>
              <td>41,140</td>
              <td><strong>53.24</strong></td>
              <td>8,228</td>
              <td>102m</td>
              <td><strong>RGB</strong></td>
              <td><strong>2D/3D bbox</strong></td>
              <td>Outdoor</td>
              <td>Single target</td>
          </tr>
          <tr>
              <td><strong>MonoMulti3D-ROPE (Ours)</strong></td>
              <td><strong>133,026</strong></td>
              <td>16.95</td>
              <td><strong>581,501</strong></td>
              <td><strong>202m</strong></td>
              <td><strong>RGB</strong></td>
              <td><strong>2D/3D bbox</strong></td>
              <td>Outdoor</td>
              <td><strong>Multiple targets</strong></td>
          </tr>
      </tbody>
    </table>
  
  
    <br>
    <p>Following resources are provided:</p>
    <div class="row" style="alignment: center">
      <div class="col-sm-3"></div>
      <div class="col-sm-3">
        <a href="https://anonymous.4open.science/r/MonoMulti-3DVG" target="_blank">
          <p style="text-align:center;">
            <img src="./imgs/github.png"><br>
            Code (GitHub)
          </p>
        </a>
      </div>
      
      <div class="col-sm-3">
        <a href="https://drive.google.com/file/d/1Qo2uUNZxo-QaniDtL6doT2V3Yaf23QP8/view?usp=drive_link" target="_blank">
          <p style="text-align:center;">
            <img src="./imgs/zip.png"><br>
            MonoMulti3D-ROPE dataset (Train, Val, Test)
          </p>
        </a>
      </div>
      <div class="col-sm-3"></div>
    </div>
  </div>

  <div class="container" id="experiment">
    <h2>
      <img src="imgs/experiment.png" alt="Logo" style="vertical-align: middle; height: 50px; margin-right: 15px;">Experiments
    </h2>
    <table class="three-line-table" style="text-align: center; width: 100%; border-collapse: collapse;">
      <caption>
          The comparison of CyclopsNet with the state-of-the-art methods on the MonoMulti3D-ROPE test set (GT bboxes). &#8593; indicates higher is better, &#8595; indicates lower is better. The best results for each metric are <strong>bolded</strong>, and the second best results are <u>underlined</u>.
      </caption>
      <!-- 定义列宽 -->
      <colgroup>
          <col style="width: 20%;"> <!-- Method 列 -->
          <col style="width: 12%;"> <!-- F1 ↑ -->
          <col style="width: 12%;"> <!-- Precision ↑ -->
          <col style="width: 12%;"> <!-- Recall ↑ -->
          <col style="width: 12%;"> <!-- TP ↑ -->
          <col style="width: 12%;"> <!-- FP ↓ -->
          <col style="width: 12%;"> <!-- FN ↓ -->
      </colgroup>
      <thead>
          <tr>
              <th>Method</th>
              <th>F1 &#8593;</th>
              <th>Precision &#8593;</th>
              <th>Recall &#8593;</th>
              <th>TP &#8593;</th>
              <th>FP &#8595;</th>
              <th>FN &#8595;</th>
          </tr>
      </thead>
      <tbody>
          <tr>
              <td>ScanRefer</td>
              <td>56.67</td>
              <td>44.19</td>
              <td>78.98</td>
              <td>48,411</td>
              <td>61,140</td>
              <td>12,884</td>
          </tr>
          <tr>
              <td>ReferIt3D</td>
              <td>58.01</td>
              <td>44.75</td>
              <td>82.41</td>
              <td>49,883</td>
              <td>61,579</td>
              <td>10,647</td>
          </tr>
          <tr>
              <td>Instancerefer</td>
              <td>58.68</td>
              <td>45.30</td>
              <td>83.27</td>
              <td>50,397</td>
              <td>60,854</td>
              <td>10,122</td>
          </tr>
          <tr>
              <td>3DVG-Trans</td>
              <td>61.71</td>
              <td>48.71</td>
              <td>84.17</td>
              <td><u>56,232</u></td>
              <td>59,221</td>
              <td>10,573</td>
          </tr>
          <tr>
              <td>3DJCG</td>
              <td>63.41</td>
              <td>49.77</td>
              <td>87.36</td>
              <td>55,657</td>
              <td><u>56,172</u></td>
              <td>8,051</td>
          </tr>
          <tr>
              <td>M3DRef-CLIP</td>
              <td><u>63.70</u></td>
              <td><u>49.82</u></td>
              <td><u>88.30</u></td>
              <td>55,954</td>
              <td>56,364</td>
              <td><u>7,416</u></td>
          </tr>
          <tr>
              <td><strong>CyclopsNet (Ours)</strong></td>
              <td><strong>69.09</strong></td>
              <td><strong>54.46</strong></td>
              <td><strong>94.47</strong></td>
              <td><strong>63,139</strong></td>
              <td><strong>52,806</strong></td>
              <td><strong>3,698</strong></td>
          </tr>
      </tbody>
    </table>
    <br>
    <table class="three-line-table" style="text-align: center; width: 100%; border-collapse: collapse;">
      <caption>
          The comparison of CyclopsNet with the state-of-the-art methods on the MonoMulti3D-ROPE test set (Pred bboxes). &#8593; indicates higher is better, &#8595; indicates lower is better. The best results for each metric are <strong>bolded</strong>, and the second best results are <u>underlined</u>.
      </caption>
      <!-- 定义列宽 -->
      <colgroup>
          <col style="width: 20%;"> <!-- Method 列 -->
          <col style="width: 12%;"> <!-- F1 ↑ -->
          <col style="width: 12%;"> <!-- Precision ↑ -->
          <col style="width: 12%;"> <!-- Recall ↑ -->
          <col style="width: 12%;"> <!-- TP ↑ -->
          <col style="width: 12%;"> <!-- FP ↓ -->
          <col style="width: 12%;"> <!-- FN ↓ -->
      </colgroup>
      <thead>
          <tr>
              <th scope="col">Method</th>
              <th scope="col">F1 &#8593;</th>
              <th scope="col">Precision &#8593;</th>
              <th scope="col">Recall &#8593;</th>
              <th scope="col">TP &#8593;</th>
              <th scope="col">FP &#8595;</th>
              <th scope="col">FN &#8595;</th>
          </tr>
      </thead>
      <tbody>
          <tr>
              <td>ScanRefer</td>
              <td>44.88</td>
              <td>39.46</td>
              <td>52.02</td>
              <td>31,704</td>
              <td>48,639</td>
              <td>29,244</td>
          </tr>
          <tr>
              <td>ReferIt3D</td>
              <td>46.13</td>
              <td>40.62</td>
              <td>53.37</td>
              <td>32,878</td>
              <td>48,054</td>
              <td>28,721</td>
          </tr>
          <tr>
              <td>Instancerefer</td>
              <td>46.17</td>
              <td>40.26</td>
              <td>54.12</td>
              <td>33,191</td>
              <td>49,247</td>
              <td>28,142</td>
          </tr>
          <tr>
              <td>3DVG-Trans</td>
              <td>47.57</td>
              <td>41.57</td>
              <td>55.59</td>
              <td>34,510</td>
              <td>48,516</td>
              <td>27,564</td>
          </tr>
          <tr>
              <td>3DJCG</td>
              <td>53.18</td>
              <td>47.19</td>
              <td>60.97</td>
              <td>40,195</td>
              <td>44,983</td>
              <td>25,799</td>
          </tr>
          <tr>
              <td>M3DRef-CLIP</td>
              <td><u>54.82</u></td>
              <td><u>48.78</u></td>
              <td><u>62.55</u></td>
              <td><u>41,579</u></td>
              <td><strong>43,657</strong></td>
              <td><u>24,891</u></td>
          </tr>
          <tr>
              <td><strong>CyclopsNet (Ours)</strong></td>
              <td><strong>60.16</strong></td>
              <td><strong>51.98</strong></td>
              <td><strong>71.40</strong></td>
              <td><strong>47,723</strong></td>
              <td><u>44,087</u></td>
              <td><strong>19,118</strong></td>
          </tr>
      </tbody>
    </table>
  
    <br><br><br>
  </div>

<style>
.three-line-table {    
    border-collapse: collapse;
    width: auto;
    margin-left: auto; /* 左边距自动 white-space: nowrap; background-color: #ADD8E6;*/
    margin-right: auto; /* 右边距自动 */
    margin-top: 20px;
}

.three-line-table th,
.three-line-table td {
    border: 1px solid transparent; /* 设置默认边框为透明 */
    padding: 4px;
    text-align: center;
}

.three-line-table thead th {
    border-bottom: 2px solid black; /* 设置标题栏底部边框为黑色 */
    border-top: 4px solid black; /* 设置标题栏顶部边框为黑色 */
    font-weight: normal; /* 确保标题栏文字不使用加粗样式 */
}

.three-line-table tbody tr {
    border-bottom: 2px solid transparent;
}

.three-line-table tbody tr:last-child {
    border-bottom: 4px solid black;
}
</style>



  <!-- Javascript includes -->
  <script src="./asset/jquery-1.8.3.min.js"></script>
  <script src="./asset/mystyle.js"></script>
  <script src="./asset/bootstrap.min.js"></script>
  <script async="" src="./asset/analytics.js"></script>
  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date();
      a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
      a.async = 1;
      a.src = g;
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-98479202-1', 'auto');
    ga('send', 'pageview');
  </script>

  <div id="point-jawn" style="z-index: 2147483647;"></div>
</body>

</html>
